{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hemanthtak2000/ResearchAssignment/blob/main/Code_research.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install essential libraries for model training, dataset handling, and evaluation\n",
        "!pip install -q transformers datasets evaluate"
      ],
      "metadata": {
        "id": "AyU4gLYkCh27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Suppress specific warning types for cleaner output\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "# Import standard data manipulation and numerical libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "# Import text preprocessing utilities\n",
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "# Visualization tools\n",
        "from wordcloud import WordCloud\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "# Sklearn tools for feature extraction, evaluation, and data splitting\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "# PyTorch and Hugging Face libraries for model development and evaluation\n",
        "import torch\n",
        "from datasets import Dataset\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "import evaluate"
      ],
      "metadata": {
        "id": "bAd-AEZBCkIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download required NLTK resources for preprocessing\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Create a lemmatizer instance\n",
        "text_lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Define a set of standard English stopwords\n",
        "stopword_list = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text_input(text_input):\n",
        "    \"\"\"\n",
        "    This function takes raw text as input and performs several preprocessing steps\n",
        "    to clean and prepare the text for NLP tasks. It converts the input to lowercase,\n",
        "    eliminates punctuation and numeric characters, splits the text into tokens,\n",
        "    removes stopwords, and applies lemmatization to convert each word to its base form.\n",
        "    Finally, the processed tokens are joined into a single cleaned string.\n",
        "\n",
        "    Parameters:\n",
        "    text_input : str\n",
        "        The raw input string to preprocess.\n",
        "\n",
        "    Returns:\n",
        "    str\n",
        "        A cleaned and lemmatized version of the original text.\n",
        "    \"\"\"\n",
        "    lowercase_text = text_input.lower()\n",
        "    text_without_symbols = re.sub(r'[^a-z\\s]', '', lowercase_text)\n",
        "    word_tokens = text_without_symbols.split()\n",
        "    filtered_tokens = [text_lemmatizer.lemmatize(token) for token in word_tokens if token not in stopword_list]\n",
        "    return ' '.join(filtered_tokens)"
      ],
      "metadata": {
        "id": "Mb4qCDwdGbLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the job-related dataset directly from a remote CSV URL\n",
        "job_dataset_df = pd.read_csv(\"https://raw.githubusercontent.com/Hemanthtak2000/ResearchAssignment/refs/heads/main/Job_Dataset.csv\")"
      ],
      "metadata": {
        "id": "fYRnmMDmCz1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preview the first few records in the job dataset\n",
        "print(job_dataset_df.head())"
      ],
      "metadata": {
        "id": "Z-Ctv0UVDVht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display dataset structure including data types and missing value info\n",
        "job_dataset_df.info()"
      ],
      "metadata": {
        "id": "wdWO5HnrGEBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rename specific columns for clarity: 'fraudulent' → 'label', 'Job_Desc' → 'text'\n",
        "job_dataset_df = job_dataset_df.rename(columns={\n",
        "    'fraudulent': 'label',\n",
        "    'Job_Desc': 'text'\n",
        "})\n",
        "# Print updated column names to verify changes\n",
        "print(job_dataset_df.columns)"
      ],
      "metadata": {
        "id": "AOgvbU2GWSHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check updated DataFrame structure and ensure there are no missing values\n",
        "job_dataset_df.info()"
      ],
      "metadata": {
        "id": "tkQpqc_OWVd-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate summary statistics for numerical features in the dataset\n",
        "job_dataset_df.describe()"
      ],
      "metadata": {
        "id": "fANwFrXzDh-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the total number of rows and columns in the dataset\n",
        "numrow_jobdet, numcol_jobdet = job_dataset_df.shape\n",
        "print(f\"The shape of the original dataset is {numrow_jobdet} reviews with {numcol_jobdet} columns.\")"
      ],
      "metadata": {
        "id": "mCgkd6IfF0rN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the number of missing values in each column of the dataset\n",
        "job_dataset_df.isna().sum()"
      ],
      "metadata": {
        "id": "wFxKmp34F6dI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new column that stores the character count of each job description\n",
        "job_dataset_df['len_of_desc'] = job_dataset_df['text'].apply(len)"
      ],
      "metadata": {
        "id": "XW0acMIfHgJc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the text cleaning function to each entry in the 'text' column\n",
        "job_dataset_df['Processed_Desc'] = job_dataset_df['text'].apply(preprocess_text_input)\n",
        "# Display original and preprocessed versions of the job descriptions\n",
        "job_dataset_df[['text', 'Processed_Desc']]"
      ],
      "metadata": {
        "id": "JNy4jpMtGCzY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify and count any duplicate entries present in the dataset\n",
        "print(f\"Number of duplicate rows in the Email Dataset : {job_dataset_df.duplicated().sum()}\")"
      ],
      "metadata": {
        "id": "5agf5GFSHrux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the column names available in the dataset after preprocessing\n",
        "job_dataset_df.columns"
      ],
      "metadata": {
        "id": "BEJVSUDkH1xL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preview the top 5 entries of the preprocessed dataset\n",
        "job_dataset_df.head()"
      ],
      "metadata": {
        "id": "U79J1C_nH-Lm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Examine the distribution of class labels in the dataset\n",
        "Jobdet_cnt = job_dataset_df['label'].value_counts()\n",
        "print(\"Number of Records per Class:\\n\", Jobdet_cnt)"
      ],
      "metadata": {
        "id": "NHTulqW8IKe_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the class distribution\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.barplot(x=Jobdet_cnt.index, y=Jobdet_cnt.values)\n",
        "plt.title(\"Distribution of Job Classification Labels\")\n",
        "plt.xlabel(\"Label (0 = Real, 1 = Fraudulent)\")\n",
        "plt.ylabel(\"Number of Job Listings\")\n",
        "plt.xticks([0, 1])\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "e8GXQAweIbzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the distribution of job description lengths\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.histplot(job_dataset_df['len_of_desc'], bins=30, kde=True)\n",
        "plt.title(\"Histogram of Job Description Lengths\")\n",
        "plt.xlabel(\"Length of Description (in Characters)\")\n",
        "plt.ylabel(\"Number of Job Listings\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gcMK53BpIqRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select numerical columns to analyze correlation\n",
        "Jobdesc_numcol = ['label', 'len_of_desc']\n",
        "# Calculate correlation matrix between selected features\n",
        "Jobdesc_CM = job_dataset_df[Jobdesc_numcol].corr()\n",
        "# Visualize the correlation matrix using a heatmap\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(Jobdesc_CM, annot=True, cmap='Blues', fmt=\".2f\")\n",
        "plt.title('Correlation Between Label and Description Length')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ocK7gS3jKUY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import resample\n",
        "# Split the dataset into majority (label = 0) and minority (label = 1) classes\n",
        "job_tgt_Major = job_dataset_df[job_dataset_df['label'] == 0]\n",
        "job_tgt_Minor = job_dataset_df[job_dataset_df['label'] == 1]\n",
        "# Perform upsampling on the minority class to balance the class distribution\n",
        "job_tgt_Min_Up = resample(\n",
        "    job_tgt_Minor,\n",
        "    replace=True,\n",
        "    n_samples=len(job_tgt_Major),\n",
        "    random_state=1107\n",
        ")\n",
        "# Merge the upsampled minority class with the original majority class\n",
        "Job_det_df_balanced = pd.concat([job_tgt_Major, job_tgt_Min_Up])\n",
        "# Randomly shuffle the rows to mix class samples evenly\n",
        "Job_det_df_balanced = Job_det_df_balanced.sample(frac=1, random_state=1107).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "QirAT83gZUA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the class label distribution after applying oversampling\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.countplot(x='label', data=Job_det_df_balanced)\n",
        "plt.title(\"Balanced Class Distribution After Upsampling\")\n",
        "plt.xlabel(\"Class Label (0 = Real, 1 = Fraudulent)\")\n",
        "plt.ylabel(\"Number of Records\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Hep1k3EMZkuk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Divide the dataset into training and testing sets while maintaining label proportions\n",
        "Jondesc_Trn_df, Jondesc_Test_df = train_test_split(\n",
        "    job_dataset_df, test_size=0.2, random_state=1107, stratify=job_dataset_df['label'])"
      ],
      "metadata": {
        "id": "9RBgekqQKtUk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform training and testing DataFrames into Hugging Face Dataset objects\n",
        "Ds_Jobdesc_trn = Dataset.from_pandas(Jondesc_Trn_df)\n",
        "Ds_Jobdesc_test = Dataset.from_pandas(Jondesc_Test_df)"
      ],
      "metadata": {
        "id": "Qa4fi2qGLYB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the tokenizer from the selected BERT model\n",
        "LLM_Model_Select = \"bert-base-uncased\"\n",
        "Bert_JD_Tknzr = AutoTokenizer.from_pretrained(LLM_Model_Select)"
      ],
      "metadata": {
        "id": "fWtP6qoqLfgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a tokenization function to process batches of text using the BERT tokenizer\n",
        "def tokenize_jobdesc_text(batch_data):\n",
        "    \"\"\"\n",
        "    Tokenizes a batch of text inputs using the loaded BERT tokenizer. This includes padding each\n",
        "    text to a uniform length and truncating texts that exceed the model's maximum input size.\n",
        "    These steps ensure the data is properly formatted for transformer-based models.\n",
        "\n",
        "    Parameters:\n",
        "    batch_data : dict\n",
        "        A dictionary containing one or more text inputs under the \"text\" key.\n",
        "\n",
        "    Returns:\n",
        "    dict\n",
        "        A dictionary with tokenized output including input IDs, attention masks, etc.\n",
        "    \"\"\"\n",
        "    return Bert_JD_Tknzr(batch_data[\"text\"], padding=\"max_length\", truncation=True)\n",
        "\n",
        "# Apply the tokenization function to the training and testing datasets\n",
        "Ds_Jobdesc_trn = Ds_Jobdesc_trn.map(tokenize_jobdesc_text, batched=True)\n",
        "Ds_Jobdesc_test = Ds_Jobdesc_test.map(tokenize_jobdesc_text, batched=True)"
      ],
      "metadata": {
        "id": "rWUv_px2L2vY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a pre-trained BERT model configured for binary text classification\n",
        "Finetuned_JD_Model = AutoModelForSequenceClassification.from_pretrained(LLM_Model_Select, num_labels=2)"
      ],
      "metadata": {
        "id": "DCh1t-LWMcr2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define key training parameters for the model\n",
        "Btch_jobdesc_Size = 8\n",
        "# Determine how often to log based on dataset size and batch size\n",
        "Jobdesc_Log_Steps = len(Ds_Jobdesc_trn) // Btch_jobdesc_Size\n",
        "# Extract model identifier from full model path (useful if custom path is given)\n",
        "LLM_Model_Select = LLM_Model_Select.split(\"/\")[-1]"
      ],
      "metadata": {
        "id": "Y5rcw_XYMzep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up model training configuration including batch size, learning rate, precision, and output handling\n",
        "TrainingArga_JobDesc = TrainingArguments(\n",
        "    output_dir=f\"{LLM_Model_Select}-Model\",\n",
        "    overwrite_output_dir=True,\n",
        "    learning_rate=2e-5,\n",
        "    weight_decay=0.01,\n",
        "    per_device_train_batch_size=Btch_jobdesc_Size,\n",
        "    per_device_eval_batch_size=Btch_jobdesc_Size,\n",
        "    push_to_hub=False,\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    logging_steps=Jobdesc_Log_Steps,\n",
        "    report_to=\"none\"\n",
        ")"
      ],
      "metadata": {
        "id": "y7DxWryMNJCW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load accuracy evaluation metric for model performance tracking\n",
        "Jobdesc_AccuracyCal = evaluate.load(\"accuracy\")\n",
        "\n",
        "# Define a metric computation function to evaluate classification accuracy\n",
        "def compute_text_classification_metrics(prediction_tuple):\n",
        "    \"\"\"\n",
        "    This function calculates the classification accuracy by comparing predicted labels\n",
        "    to true labels. It processes the raw logits from the model to determine the\n",
        "    predicted class, and then uses an accuracy metric to assess performance.\n",
        "\n",
        "    Parameters:\n",
        "    prediction_tuple : tuple\n",
        "        Contains the model’s raw output logits and the true labels.\n",
        "\n",
        "    Returns:\n",
        "    dict\n",
        "        Contains the computed accuracy score.\n",
        "    \"\"\"\n",
        "    Jobdesc_Logits, Jobdesc_labels = prediction_tuple\n",
        "    Jobdesc_preds = torch.argmax(torch.tensor(Jobdesc_Logits), dim=-1)\n",
        "    return Jobdesc_AccuracyCal.compute(predictions=Jobdesc_preds, references=Jobdesc_labels)"
      ],
      "metadata": {
        "id": "HyIqmNhKNetG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Trainer class with model, data, training arguments, and evaluation function\n",
        "Jobdesc_Trainer_det = Trainer(\n",
        "    model=Finetuned_JD_Model,\n",
        "    args=TrainingArga_JobDesc,\n",
        "    train_dataset=Ds_Jobdesc_trn,\n",
        "    eval_dataset=Ds_Jobdesc_test,\n",
        "    compute_metrics=compute_text_classification_metrics\n",
        ")\n",
        "# Begin model training\n",
        "Jobdesc_Trainer_det.train()"
      ],
      "metadata": {
        "id": "mJHX5NSmN5-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assess model performance using the test dataset\n",
        "Jobdesc_Model_Eval = Jobdesc_Trainer_det.evaluate()\n",
        "# Display evaluation results for the fine-tuned model on the job description data\n",
        "print(\"Model Evaluation Summary on Job Classification Task:\")\n",
        "for key, value in Jobdesc_Model_Eval.items():\n",
        "    print(f\"{key}: {value:.4f}\")"
      ],
      "metadata": {
        "id": "EPk79lHaOHp_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate predictions using the trained model and evaluate classification performance\n",
        "Jobdesc_Model_Pred = Jobdesc_Trainer_det.predict(Ds_Jobdesc_test)\n",
        "Actual_Values = Jobdesc_Model_Pred.label_ids\n",
        "Jobdesc_Pred_Values = torch.argmax(torch.tensor(Jobdesc_Model_Pred.predictions), axis=1).numpy()\n",
        "# Plot confusion matrix based on actual vs predicted labels\n",
        "Eval_Jobdesc_ConfMat = confusion_matrix(Actual_Values, Jobdesc_Pred_Values)\n",
        "Disp_Jobdesc_Confmat = ConfusionMatrixDisplay(confusion_matrix=Eval_Jobdesc_ConfMat)\n",
        "Disp_Jobdesc_Confmat.plot(cmap=\"Blues\", values_format=\"d\")\n",
        "plt.title(\"Confusion Matrix for Job Description Classification\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "S-BBKZdxObJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract raw job descriptions from the test dataset\n",
        "Jobdesc_testing_Samples = Ds_Jobdesc_test[\"text\"]\n",
        "\n",
        "# Display a mix of prediction results (some 0s and some 1s)\n",
        "print(\"\\nSample Predictions from the Test Dataset:\\n\")\n",
        "shown_labels = {0: 0, 1: 0}\n",
        "i = 0\n",
        "\n",
        "while sum(shown_labels.values()) < 6 and i < len(Jobdesc_Pred_Values):\n",
        "    pred_label = Jobdesc_Pred_Values[i]\n",
        "\n",
        "    if shown_labels[pred_label] < 2:  # Show up to 2 from each class\n",
        "        print(f\"Text: {Jobdesc_testing_Samples[i]}\")\n",
        "        print(f\"Predicted Label : {pred_label}, True Label: {Actual_Values[i]}\")\n",
        "        print(\"-\" * 60)\n",
        "        shown_labels[pred_label] += 1\n",
        "\n",
        "    i += 1\n"
      ],
      "metadata": {
        "id": "ws3ALMNjPIsD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}